{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bdfb4b",
   "metadata": {},
   "source": [
    "# Scraping data From Zameen.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4093177",
   "metadata": {},
   "source": [
    "## Step 1: Importing required Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e2cd501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests # Sends the Http requests to get the web page\n",
    "import pandas as pd # used in last for creating and importing Data Frame\n",
    "from bs4 import BeautifulSoup #used to parse the Html content of the web page\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e170c0",
   "metadata": {},
   "source": [
    "# Step 2: Inital URL to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4d7133",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_url = \"https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-1.html\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"} # this code mimic as the i am a browser who is requesting for the page to open\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadcf128",
   "metadata": {},
   "source": [
    "# Step 3: make a vraibale that recives the grabed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fc3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list that store all the extracted data in the variable\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3b235",
   "metadata": {},
   "source": [
    "# Step 4: the big and tricky step "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa385e",
   "metadata": {},
   "source": [
    "###  Step 4 is explained below with comments for you ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd89ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-1.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-2.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-3.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-4.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-5.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-6.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-7.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-8.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-9.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-10.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-11.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-12.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-13.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-14.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-15.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-16.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-17.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-18.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-19.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-20.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-21.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-22.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-23.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-24.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-25.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-26.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-27.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-28.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-29.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-30.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-31.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-32.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-33.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-34.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-35.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-36.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-37.html\n",
      "scraping: https://www.zameen.com/Homes/Islamabad_Bahria_Town-383-38.html\n",
      "\n",
      "Reached last page.\n"
     ]
    }
   ],
   "source": [
    "# Doing the loop as the structure and classes values in pagination is same( Pagiantion means a webpage having multiple pages in it) \n",
    "while True:\n",
    "    # print out the Step wise grabed URL from the previos page one by one\n",
    "    # but at first  loop is assigned url is the one given in step 2\n",
    "\n",
    "    print(f\"scraping: {current_url}\")\n",
    "\n",
    "    #________________________________________________\n",
    "\n",
    "    # Here I uses try and except here because during grabing a massave wedata any error can happen.\n",
    "\n",
    "    try:\n",
    "        r = requests.get(current_url, headers=headers) # requesting the current page\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\") # parsing the current page\n",
    "        # above for faster parsing you can Use \"lxml\" in place of \"html.parser\".\n",
    "\n",
    "        # Step 1: Get all listings/cards on the page\n",
    "        listings = soup.find_all(\"div\", class_=\"d3b6a76b _43afd188\")  # calsses may change over time\n",
    "\n",
    "        # Step 2: Loop through each listing\n",
    "        for card in listings:\n",
    "            # here i am using error handling method because if there is no data for any variable below like if no pice mension than what to do\n",
    "            try:\n",
    "                price = card.find(\"span\", class_=\"dc381b54\").text.strip()\n",
    "            except:\n",
    "                price = None\n",
    "\n",
    "            try:\n",
    "                location = card.find(\"div\", class_=\"db1aca2f\").text.strip()\n",
    "            except:\n",
    "                location = None\n",
    "\n",
    "            try:\n",
    "                added_time = card.find(\"span\", class_=\"a018d4bd\").text.strip().replace(\"Added: \", \"\")\n",
    "            except:\n",
    "                added_time = None\n",
    "\n",
    "            try:\n",
    "                heading = card.find(\"h2\", class_=\"_36dfb99f\").text.strip()\n",
    "            except:\n",
    "                heading = None\n",
    "            \n",
    "            # This is a very important part\n",
    "            # The tags and classes are same for bedrooms, bathrooms, area.\n",
    "            # But they are diffrent only based on the lable assigned data.\n",
    "            # So I used filter the data with lable\n",
    "\n",
    "            bedrooms = bathrooms = area = None\n",
    "            try:\n",
    "                features = card.find_all(\"span\", class_=\"_6d9b9b83\")\n",
    "                for feature in features:\n",
    "                    label = feature.get(\"aria-label\", \"\").lower()\n",
    "                    if label == \"beds\":\n",
    "                        bedrooms = feature.text.strip()\n",
    "                    elif label == \"baths\":\n",
    "                        bathrooms = feature.text.strip()\n",
    "                    elif label == \"area\":\n",
    "                        area_span = feature.find(\"span\")\n",
    "                        if area_span:\n",
    "                            area = area_span.text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # This is the new short code method I found  to append data to the list so we can easily later convert it to a dataframe\n",
    "            data.append({\n",
    "                \"Price\": price,\n",
    "                \"Address\": location,\n",
    "                \"Bedrooms\": bedrooms,\n",
    "                \"Bathrooms\": bathrooms,\n",
    "                \"Area\": area,\n",
    "                \"Heading\": heading,\n",
    "                \"Added Time\": added_time\n",
    "            })\n",
    "\n",
    "        # Step 3: Find and follow the \"Next\" button ( means find the URL Hidden in the Next button so we cahnge current Url to this url)\n",
    "        next_btn = soup.find(\"a\", {\"title\": \"Next\"})\n",
    "        if next_btn and next_btn.get(\"href\"):\n",
    "            # change the old url to the next button url\n",
    "            current_url = \"https://www.zameen.com\" + next_btn.get(\"href\")\n",
    "        else:\n",
    "            print(\"\\nReached last page.\")\n",
    "            break\n",
    "\n",
    "        time.sleep(1) # wait for the little amount of time to scrap another link\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9637088",
   "metadata": {},
   "source": [
    "# Step 4: Convert list of Dict to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6d880b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Price                                     Address Bedrooms  \\\n",
      "0      4.6 Crore  Bahria Enclave - Sector C3, Bahria Enclave        5   \n",
      "1      2.7 Crore                 Bahria Enclave, Bahria Town        3   \n",
      "2      1.6 Crore                 Bahria Enclave, Bahria Town        2   \n",
      "3     2.95 Crore                 Bahria Enclave, Bahria Town        3   \n",
      "4     1.55 Crore                 Bahria Enclave, Bahria Town        2   \n",
      "...          ...                                         ...      ...   \n",
      "997   1.85 Crore   Bahria Enclave - Sector I, Bahria Enclave     None   \n",
      "998   4.15 Crore   Bahria Enclave - Sector M, Bahria Enclave        5   \n",
      "999    2.1 Crore   Bahria Enclave - Sector N, Bahria Enclave        3   \n",
      "1000   1.4 Crore   Bahria Enclave - Sector N, Bahria Enclave        3   \n",
      "1001     5 Crore   Bahria Enclave - Sector N, Bahria Enclave        6   \n",
      "\n",
      "     Bathrooms        Area                                            Heading  \\\n",
      "0            6    10 Marla  Sector C3 10 Marla Brand New House Heighted Lo...   \n",
      "1            3   9.6 Marla  Best Options For Flat Is Available For Sale In...   \n",
      "2            2   6.4 Marla  Flat Of 1450 Square Feet Is Available In Conte...   \n",
      "3            3   9.6 Marla      2150 Square Feet Flat For Sale In Bahria Town   \n",
      "4            2   5.6 Marla  Ideal Flat In Islamabad Available For Rs. 1550...   \n",
      "...        ...         ...                                                ...   \n",
      "997       None     8 Marla           Top Penthouse - Fully Furnished For Sale   \n",
      "998          6    10 Marla  10 Marla Beautiful Brand New House Is Availabl...   \n",
      "999          5     5 Marla  5 Marla Beautiful House Available For Sale Own...   \n",
      "1000         3   7.5 Marla                          Luxury Apartment on Sale!   \n",
      "1001         6  10.5 Marla  Bahria Enclave 8 Marla House 2.5 Marla Extra L...   \n",
      "\n",
      "       Added Time  \n",
      "0       1 day ago  \n",
      "1       1 day ago  \n",
      "2       1 day ago  \n",
      "3       1 day ago  \n",
      "4       1 day ago  \n",
      "...           ...  \n",
      "997   1 month ago  \n",
      "998   4 weeks ago  \n",
      "999   4 weeks ago  \n",
      "1000  4 weeks ago  \n",
      "1001  1 month ago  \n",
      "\n",
      "[1002 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# As we arranged out data in dict (key: value) data type so just online o fcode will convert it to a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd33e9",
   "metadata": {},
   "source": [
    "# Step 5: Save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df974d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the DataFrame to CSV file\n",
    "df.to_csv(\"zameen_bahria_town.csv\", index=False)\n",
    "\n",
    "# OR convert the csv to Excel file\n",
    "import openpyxl\n",
    "\n",
    "df.to_excel(\"zameen_bahria_town.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
